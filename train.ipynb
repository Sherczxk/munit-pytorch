{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-1-8cc6da301239>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-8cc6da301239>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    from data import get_train_dataï¼Œget_test_data,save_image\u001b[0m\n\u001b[1;37m                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from option import TrainOptions\n",
    "from data import get_train_data,get_test_data,save_image\n",
    "import munit_trainer\n",
    "import tensorboardX\n",
    "import os \n",
    "\n",
    "opt = TrainOptions().parse()\n",
    "\n",
    "trainer = munit_trainer(opt)\n",
    "trainer.cuda()\n",
    "\n",
    "##################################################################\n",
    "# loading data --------------------------------------------\n",
    "trainA, trainB = get_train_data(opt.datadir,opt.batch_size,\\\n",
    "                 opt.num_workers,opt.new_size,opt.crop_size)\n",
    "                 \n",
    "testA, testB = get_test_data(opt.datadir,opt.batch_size,\\\n",
    "               opt.num_workers,opt.new_size,opt.crop_size)\n",
    "               \n",
    "train_display_A = torch.stack([trainA.dataset[i] for i in range(opt.display_size)],-1).cuda()\n",
    "train_display_B = torch.stack([trainB.dataset[i] for i in range(opt.display_size)],-1).cuda()\n",
    "test_display_A = torch.stack([testA.dataset[i] for i in range(opt.display_size)],-1).cuda()\n",
    "test_display_B = torch.stack([testB.dataset[i] for i in range(opt.display_size)],-1).cuda()\n",
    "               \n",
    "               \n",
    "# output dir ------------------------------------------------\n",
    "log_path = os.path.join(opt.output_path,'/logs',opt.exp_name)\n",
    "save_image_path = os.path.join(opt.output_path,'/output',opt.exp_name,'/image')\n",
    "save_checkpoint_path = os.path.join(opt.output_path,'/output',opt.exp_name,'/checkpoint')\n",
    "\n",
    "for path in [log_path,save_image_path,save_checkpoint_path]:\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "        \n",
    "train_sum = tensorboardX.SummaryWriter(os.path)\n",
    "\n",
    "# start training ---------------------------------------------\n",
    "for iter in range(opt.max_iter):\n",
    "    for it,(x_a,x_b) in enumerate(zip(trainA,trainB)):\n",
    "        x_a,x_b = x_a.cuda().detach(),x_b.cuda().detach()\n",
    "        \n",
    "    trianer.optimize_parameters(x_a,x_b)\n",
    "    \n",
    "    # update and save log file\n",
    "    if (iter+1) % opt.log_save_iter ==0:\n",
    "        print('Iteration: %08d/%08d' % (iter+1,opt.max_iter))\n",
    "        members = []\n",
    "        for attr in dir (trainer):\n",
    "            if not callable(getattr(trainer,attr)) and not attr.startswith(\"__\") \\\n",
    "            and ('loss' in attr or 'grad' in attr or 'nwd' in attr):\n",
    "                members.append(attr)\n",
    "        for m in members:\n",
    "            train_sum.add_scalar(m,getattr(trainer,m),iter+q)\n",
    "        \n",
    "    # save current model\n",
    "    if (iter+1) % opt.model_save_iter == 0:\n",
    "        trainer.save(save_checkpoint_path,iter)\n",
    "        \n",
    "    # save sample images\n",
    "    if (iter+1) % opt.image_save_iter == 0:\n",
    "        with torch.no_grad():\n",
    "            # train_a2b = [num_style*display_size,c,h,w]\n",
    "            train_a2b,train_b2a = trainer.sample(train_display_A,train_display_B,opt.num_style)\n",
    "            test_a2b,test_b2a = trainer.sample(test_display_A,test_display_B,opt.num_style)\n",
    "            # sample_train = [2*(1+num_style)*display_size,c,h,w]\n",
    "            sample_train = torch.cat(tuple([train_display_A,train_a2b,train_display_B,train_b2a]))\n",
    "            sample_test = torch.cat(tuple([test_display_A,test_a2b,test_display_B,test_b2a]))\n",
    "            # save sample images\n",
    "            save_image(sample_train,save_image_path+'/train_%08d.jpg'%(iter+1))\n",
    "            save_image(sample_test,save_image_path+'/test_%08d.jpg'%(iter+1))\n",
    "            \n",
    "    # display current translate images\n",
    "    if (iter+1) % opt.image_display_iter == 0:\n",
    "        with torch.no_grad():\n",
    "            train_a2b,train_b2a = trainer.sample(train_display_A,train_display_B,opt.num_style)\n",
    "            sample_train = torch.cat(tuple([train_display_A,train_a2b,train_display_B,train_b2a]))\n",
    "            save_image(sample_train,save_image_path+'/train_current.jpg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
